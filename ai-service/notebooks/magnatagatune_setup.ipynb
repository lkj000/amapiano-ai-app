{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MagnaTagATune Dataset Setup for Jupyter Notebook\n",
    "\n",
    "**Purpose**: Download and prepare the MagnaTagATune dataset for Amapiano model training\n",
    "\n",
    "**What this does**:\n",
    "1. Downloads ~2.9GB of audio from HuggingFace mirror\n",
    "2. Extracts ~25,863 MP3 files\n",
    "3. Filters for Amapiano-relevant proxy tags\n",
    "4. Creates training-ready subset\n",
    "\n",
    "**Requirements**:\n",
    "- ~10GB free disk space\n",
    "- Stable internet connection\n",
    "- 10-30 minutes depending on download speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q pandas tqdm requests\n",
    "\n",
    "print(\"âœ… Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download MagnaTagATune Dataset\n",
    "\n",
    "This downloads the complete dataset from HuggingFace's mirror (~2.9GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Configuration\n",
    "DATASET_URL = \"https://huggingface.co/datasets/confit/magnatagatune/resolve/main/mp3.zip\"\n",
    "DATASET_DIR = Path(\"../datasets/magnatagatune\")\n",
    "ZIP_PATH = DATASET_DIR / \"mp3.zip\"\n",
    "MP3_DIR = DATASET_DIR / \"mp3\"\n",
    "\n",
    "DATASET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def download_with_progress(url, dest_path):\n",
    "    \"\"\"Download file with tqdm progress bar\"\"\"\n",
    "    response = urllib.request.urlopen(url)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    block_size = 8192\n",
    "    progress_bar = tqdm(total=total_size, unit='B', unit_scale=True, desc=\"Downloading\")\n",
    "    \n",
    "    with open(dest_path, 'wb') as f:\n",
    "        while True:\n",
    "            buffer = response.read(block_size)\n",
    "            if not buffer:\n",
    "                break\n",
    "            f.write(buffer)\n",
    "            progress_bar.update(len(buffer))\n",
    "    \n",
    "    progress_bar.close()\n",
    "\n",
    "# Download\n",
    "if not ZIP_PATH.exists():\n",
    "    print(\"ðŸ“¥ Downloading MagnaTagATune dataset (~2.9GB)...\")\n",
    "    print(\"This may take 10-30 minutes depending on your connection\")\n",
    "    download_with_progress(DATASET_URL, ZIP_PATH)\n",
    "    print(f\"âœ… Downloaded to {ZIP_PATH}\")\n",
    "else:\n",
    "    print(f\"âœ… Dataset already downloaded at {ZIP_PATH}\")\n",
    "\n",
    "# Extract\n",
    "if not MP3_DIR.exists() or not any(MP3_DIR.rglob(\"*.mp3\")):\n",
    "    print(\"\\nðŸ“¦ Extracting MP3 files...\")\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(MP3_DIR)\n",
    "    \n",
    "    mp3_files = list(MP3_DIR.rglob(\"*.mp3\"))\n",
    "    print(f\"âœ… Extracted {len(mp3_files)} MP3 files\")\n",
    "    \n",
    "    if len(mp3_files) < 20000:\n",
    "        print(f\"âš ï¸  Expected ~25,863 files, found {len(mp3_files)}\")\n",
    "else:\n",
    "    mp3_files = list(MP3_DIR.rglob(\"*.mp3\"))\n",
    "    print(f\"âœ… MP3 files already extracted ({len(mp3_files)} files)\")\n",
    "\n",
    "# Optional: Clean up ZIP to save space\n",
    "cleanup = input(\"\\nDelete ZIP file to save ~2.9GB? (y/n): \")\n",
    "if cleanup.lower() == 'y':\n",
    "    ZIP_PATH.unlink()\n",
    "    print(\"ðŸ—‘ï¸  ZIP file removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS_URL = \"https://mirg.city.ac.uk/datasets/magnatagatune/annotations_final.csv\"\n",
    "ANNOTATIONS_PATH = DATASET_DIR / \"annotations_final.csv\"\n",
    "\n",
    "if not ANNOTATIONS_PATH.exists():\n",
    "    print(\"ðŸ“¥ Downloading annotations...\")\n",
    "    urllib.request.urlretrieve(ANNOTATIONS_URL, ANNOTATIONS_PATH)\n",
    "    print(f\"âœ… Annotations downloaded to {ANNOTATIONS_PATH}\")\n",
    "else:\n",
    "    print(f\"âœ… Annotations already exist at {ANNOTATIONS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load and Explore Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load annotations\n",
    "df = pd.read_csv(ANNOTATIONS_PATH, sep='\\t')\n",
    "\n",
    "print(f\"Total clips: {len(df):,}\")\n",
    "print(f\"Tag columns: {len(df.columns)}\")\n",
    "print(f\"\\nFirst few columns: {list(df.columns[:10])}\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "\n",
    "# Show sample\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Filter for Amapiano Proxy Tags\n",
    "\n",
    "We filter for tracks with characteristics similar to Amapiano:\n",
    "- Drums/percussion/beats\n",
    "- Piano/keyboard/jazz elements  \n",
    "- Bass/deep basslines\n",
    "- House/electronic/dance vibes\n",
    "- Chill/soulful atmosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Amapiano proxy tags\n",
    "AMAPIANO_PROXY_TAGS = {\n",
    "    'drums', 'percussion', 'beats', 'techno', 'electronic',\n",
    "    'piano', 'keyboard', 'jazzy', 'chords', 'jazz',\n",
    "    'bass', 'bassline', 'deep',\n",
    "    'house', 'dance', 'groove',\n",
    "    'chill', 'mellow', 'soulful', 'soft',\n",
    "    'instrumental', 'ambient'\n",
    "}\n",
    "\n",
    "MIN_TAGS_MATCH = 3\n",
    "TARGET_CLIPS = 8000\n",
    "\n",
    "# Get tag columns\n",
    "tag_columns = [col for col in df.columns if col not in ['clip_id', 'mp3_path']]\n",
    "\n",
    "# Count matching tags for each clip\n",
    "def count_matching_tags(row):\n",
    "    matching = 0\n",
    "    for tag in tag_columns:\n",
    "        if tag.lower() in AMAPIANO_PROXY_TAGS and row[tag] == 1:\n",
    "            matching += 1\n",
    "    return matching\n",
    "\n",
    "df['amapiano_proxy_score'] = df.apply(count_matching_tags, axis=1)\n",
    "\n",
    "# Filter and sort\n",
    "filtered = df[df['amapiano_proxy_score'] >= MIN_TAGS_MATCH].copy()\n",
    "filtered = filtered.sort_values('amapiano_proxy_score', ascending=False)\n",
    "\n",
    "print(f\"\\nâœ… Filtered to {len(filtered):,} clips with â‰¥{MIN_TAGS_MATCH} Amapiano proxy tags\")\n",
    "print(f\"\\nScore distribution:\")\n",
    "print(filtered['amapiano_proxy_score'].value_counts().sort_index(ascending=False))\n",
    "\n",
    "# Limit to target\n",
    "if len(filtered) > TARGET_CLIPS:\n",
    "    filtered = filtered.head(TARGET_CLIPS)\n",
    "    print(f\"\\nâœ‚ï¸  Limited to top {TARGET_CLIPS} clips by proxy score\")\n",
    "\n",
    "filtered.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create Training Subset\n",
    "\n",
    "Copy filtered audio files to a dedicated training directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "OUTPUT_DIR = Path(\"../datasets/amapiano_proxy\")\n",
    "AUDIO_DIR = OUTPUT_DIR / \"audio\"\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "AUDIO_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Build file lookup map\n",
    "all_mp3s = {f.name: f for f in MP3_DIR.rglob(\"*.mp3\")}\n",
    "print(f\"Built lookup map for {len(all_mp3s):,} MP3 files\")\n",
    "\n",
    "# Copy files\n",
    "metadata_rows = []\n",
    "copied = 0\n",
    "skipped = 0\n",
    "\n",
    "print(f\"\\nðŸ“‹ Copying {len(filtered)} audio files...\")\n",
    "\n",
    "for idx, row in tqdm(filtered.iterrows(), total=len(filtered), desc=\"Copying\"):\n",
    "    clip_id = row.get('clip_id', idx)\n",
    "    mp3_path = row.get('mp3_path', f\"{clip_id}.mp3\")\n",
    "    mp3_filename = Path(mp3_path).name\n",
    "    \n",
    "    # Find source file\n",
    "    source_file = MP3_DIR / mp3_path\n",
    "    if not source_file.exists() and mp3_filename in all_mp3s:\n",
    "        source_file = all_mp3s[mp3_filename]\n",
    "    \n",
    "    if source_file.exists():\n",
    "        dest_file = AUDIO_DIR / f\"{clip_id}.mp3\"\n",
    "        shutil.copy2(source_file, dest_file)\n",
    "        \n",
    "        # Get active tags\n",
    "        tag_list = [col for col in tag_columns if row[col] == 1]\n",
    "        \n",
    "        metadata_rows.append({\n",
    "            'clip_id': clip_id,\n",
    "            'file_path': str(dest_file.relative_to(OUTPUT_DIR)),\n",
    "            'amapiano_proxy_score': row['amapiano_proxy_score'],\n",
    "            'tags': ','.join(tag_list),\n",
    "            'duration': 29.0\n",
    "        })\n",
    "        copied += 1\n",
    "    else:\n",
    "        skipped += 1\n",
    "\n",
    "# Save metadata\n",
    "metadata_df = pd.DataFrame(metadata_rows)\n",
    "metadata_path = OUTPUT_DIR / \"training_metadata.csv\"\n",
    "metadata_df.to_csv(metadata_path, index=False)\n",
    "\n",
    "print(f\"\\nâœ… Training subset created:\")\n",
    "print(f\"   ðŸ“ {copied:,} audio files copied\")\n",
    "print(f\"   â­ï¸  {skipped:,} files skipped (not found)\")\n",
    "print(f\"   ðŸ“Š Metadata: {metadata_path}\")\n",
    "print(f\"   â±ï¸  Total duration: {copied * 29 / 3600:.1f} hours\")\n",
    "print(f\"   ðŸ’¾ Dataset size: ~{copied * 1.2 / 1024:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AMAPIANO PROXY TRAINING DATASET STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total clips: {len(metadata_df):,}\")\n",
    "print(f\"Estimated duration: {len(metadata_df) * 29 / 3600:.1f} hours\")\n",
    "\n",
    "print(f\"\\nProxy score distribution:\")\n",
    "print(metadata_df['amapiano_proxy_score'].value_counts().sort_index(ascending=False))\n",
    "\n",
    "# Tag frequency\n",
    "all_tags = []\n",
    "for tags_str in metadata_df['tags']:\n",
    "    all_tags.extend(tags_str.split(','))\n",
    "\n",
    "tag_counts = Counter(all_tags)\n",
    "\n",
    "print(f\"\\nTop 20 most common tags:\")\n",
    "for tag, count in tag_counts.most_common(20):\n",
    "    print(f\"  {tag}: {count:,} ({count/len(metadata_df)*100:.1f}%)\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Sample Audio Preview (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import random\n",
    "\n",
    "# Pick a random high-scoring clip\n",
    "high_score = metadata_df[metadata_df['amapiano_proxy_score'] >= 5].sample(1).iloc[0]\n",
    "\n",
    "print(f\"Sample clip: {high_score['clip_id']}\")\n",
    "print(f\"Proxy score: {high_score['amapiano_proxy_score']}\")\n",
    "print(f\"Tags: {high_score['tags']}\")\n",
    "\n",
    "audio_path = OUTPUT_DIR / high_score['file_path']\n",
    "display(ipd.Audio(str(audio_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Complete!\n",
    "\n",
    "Your Amapiano proxy training dataset is ready at:\n",
    "```\n",
    "../datasets/amapiano_proxy/\n",
    "â”œâ”€â”€ audio/           # MP3 files\n",
    "â””â”€â”€ training_metadata.csv  # Training metadata\n",
    "```\n",
    "\n",
    "**Next steps**:\n",
    "1. Use this dataset with `train_musicgen.py` for fine-tuning\n",
    "2. Optionally add real Amapiano samples for better quality\n",
    "3. Run training and evaluate results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

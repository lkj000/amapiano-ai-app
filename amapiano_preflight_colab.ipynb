{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Amapiano AI - MagnaTagATune Training Setup\n",
        "\n",
        "**Purpose**: Train MusicGen on filtered MagnaTagATune dataset as Amapiano proxy\n",
        "\n",
        "**Dataset**: 1,582 clips with electronic/jazzy/drum characteristics\n",
        "\n",
        "**Duration**: 1-2 hours for quick test, 8-12 hours for full training\n",
        "\n",
        "**Cost**: $0-10 (Colab Pro)\n",
        "\n",
        "---\n",
        "\n",
        "## Training Options\n",
        "1. **Quick Test (1 epoch)**: Validate pipeline works (~1-2 hours)\n",
        "2. **Short Training (5 epochs)**: Initial results (~4-6 hours)\n",
        "3. **Full Training (20 epochs)**: Best results (~16-20 hours)"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Mount Google Drive (for checkpoint persistence)"
      ],
      "metadata": {
        "id": "step1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.makedirs('/content/drive/MyDrive/amapiano-training', exist_ok=True)\n",
        "print(\"âœ… Google Drive mounted successfully\")"
      ],
      "metadata": {
        "id": "mount_drive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: GPU Verification"
      ],
      "metadata": {
        "id": "step2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(\"\\nâœ… GPU AVAILABLE - Ready for training\")\n",
        "else:\n",
        "    print(\"âŒ GPU NOT AVAILABLE\")\n",
        "    print(\"âš ï¸  Go to Runtime > Change runtime type > Select GPU\")\n",
        "    raise RuntimeError(\"GPU required for training\")"
      ],
      "metadata": {
        "id": "gpu_check"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Clone Repository & Install Dependencies"
      ],
      "metadata": {
        "id": "step3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repo (replace with your GitHub URL if you've pushed it)\n",
        "!git clone https://github.com/YOUR_USERNAME/amapiano-ai.git\n",
        "%cd amapiano-ai\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -q torch torchaudio transformers audiocraft datasets librosa pandas tqdm\n",
        "\n",
        "print(\"âœ… Dependencies installed\")"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Download & Filter MagnaTagATune Dataset\n",
        "\n",
        "This creates the filtered dataset with ~1,582 clips matching Amapiano-proxy characteristics."
      ],
      "metadata": {
        "id": "step4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import os\n",
        "os.chdir('/content/amapiano-ai/ai-service')\n",
        "\n",
        "# Download and filter the full dataset\n",
        "!python dataset_setup.py \\\n",
        "  --output_dir ../datasets/amapiano_proxy \\\n",
        "  --min_score 3\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "metadata_path = Path('../datasets/amapiano_proxy/training_metadata.csv')\n",
        "\n",
        "if metadata_path.exists():\n",
        "    df = pd.read_csv(metadata_path)\n",
        "    print(f\"\\nâœ… DATASET CREATED SUCCESSFULLY\")\n",
        "    print(f\"   Total clips: {len(df)}\")\n",
        "    print(f\"   Audio files: {len(list(Path('../datasets/amapiano_proxy/audio').glob('*.mp3')))}\")\n",
        "    print(f\"   Total size: {sum(f.stat().st_size for f in Path('../datasets/amapiano_proxy/audio').glob('*.mp3')) / 1e9:.2f} GB\")\n",
        "    print(f\"\\nTop characteristics:\")\n",
        "    print(df['characteristics'].value_counts().head(10))\n",
        "else:\n",
        "    print(\"âŒ DATASET NOT CREATED\")\n",
        "    raise RuntimeError(\"Dataset creation failed\")"
      ],
      "metadata": {
        "id": "dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Choose Your Training Mode\n",
        "\n",
        "Select ONE of the following cells to run based on your needs:"
      ],
      "metadata": {
        "id": "step5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option A: Quick Pipeline Test (1 epoch, 100 samples)\n",
        "**Duration**: ~15-30 minutes  \n",
        "**Purpose**: Verify everything works before longer training"
      ],
      "metadata": {
        "id": "option_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!python train_musicgen.py \\\n",
        "  --data_dir ../datasets/amapiano_proxy/audio \\\n",
        "  --metadata ../datasets/amapiano_proxy/training_metadata.csv \\\n",
        "  --epochs 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --max_samples 100 \\\n",
        "  --output_dir /content/drive/MyDrive/amapiano-training/quick-test\n",
        "\n",
        "print(\"\\nâœ… Quick test complete! Check logs above for any errors.\")"
      ],
      "metadata": {
        "id": "quick_test"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option B: Short Training (5 epochs, full dataset)\n",
        "**Duration**: ~4-6 hours  \n",
        "**Purpose**: Get initial trained model for evaluation"
      ],
      "metadata": {
        "id": "option_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!python train_musicgen.py \\\n",
        "  --data_dir ../datasets/amapiano_proxy/audio \\\n",
        "  --metadata ../datasets/amapiano_proxy/training_metadata.csv \\\n",
        "  --epochs 5 \\\n",
        "  --batch_size 2 \\\n",
        "  --output_dir /content/drive/MyDrive/amapiano-training/5-epoch\n",
        "\n",
        "print(\"\\nâœ… 5-epoch training complete!\")"
      ],
      "metadata": {
        "id": "short_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option C: Full Training (20 epochs, full dataset)\n",
        "**Duration**: ~16-20 hours  \n",
        "**Purpose**: Best possible results with current dataset  \n",
        "**Note**: Run overnight or use Colab Pro for longer sessions"
      ],
      "metadata": {
        "id": "option_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!python train_musicgen.py \\\n",
        "  --data_dir ../datasets/amapiano_proxy/audio \\\n",
        "  --metadata ../datasets/amapiano_proxy/training_metadata.csv \\\n",
        "  --epochs 20 \\\n",
        "  --batch_size 2 \\\n",
        "  --output_dir /content/drive/MyDrive/amapiano-training/20-epoch\n",
        "\n",
        "print(\"\\nâœ… Full 20-epoch training complete!\")"
      ],
      "metadata": {
        "id": "full_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Verify Training Checkpoint"
      ],
      "metadata": {
        "id": "step6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Check which output directory you used\n",
        "output_dirs = [\n",
        "    \"/content/drive/MyDrive/amapiano-training/quick-test\",\n",
        "    \"/content/drive/MyDrive/amapiano-training/5-epoch\",\n",
        "    \"/content/drive/MyDrive/amapiano-training/20-epoch\"\n",
        "]\n",
        "\n",
        "for output_dir in output_dirs:\n",
        "    checkpoint_dir = Path(output_dir)\n",
        "    if checkpoint_dir.exists():\n",
        "        checkpoint_files = list(checkpoint_dir.glob('*.pt')) + list(checkpoint_dir.glob('*.pth'))\n",
        "        \n",
        "        if checkpoint_files:\n",
        "            print(f\"\\nâœ… Checkpoints found in {output_dir}\")\n",
        "            for ckpt_file in checkpoint_files:\n",
        "                print(f\"   - {ckpt_file.name} ({ckpt_file.stat().st_size / 1e6:.1f} MB)\")\n",
        "            \n",
        "            # Try to load the checkpoint\n",
        "            try:\n",
        "                ckpt = torch.load(checkpoint_files[0], map_location='cpu')\n",
        "                print(f\"\\n   âœ… Checkpoint is loadable\")\n",
        "                print(f\"   Keys: {list(ckpt.keys())[:5]}...\")\n",
        "                if 'epoch' in ckpt:\n",
        "                    print(f\"   Epoch: {ckpt['epoch']}\")\n",
        "                if 'loss' in ckpt:\n",
        "                    print(f\"   Loss: {ckpt['loss']:.4f}\")\n",
        "            except Exception as e:\n",
        "                print(f\"   âš ï¸  Warning: Could not load checkpoint: {e}\")\n",
        "        else:\n",
        "            print(f\"   No checkpoints found in {output_dir}\")\n",
        "\n",
        "print(\"\\nâœ… Checkpoint verification complete\")"
      ],
      "metadata": {
        "id": "checkpoint_verify"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Generate Test Sample\n",
        "\n",
        "Generate a sample to hear the results (requires trained model)"
      ],
      "metadata": {
        "id": "step7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Add generation code once train_musicgen.py includes generation capability\n",
        "# For now, you'll need to load the model manually and generate\n",
        "\n",
        "print(\"âš ï¸  Generation code to be added\")\n",
        "print(\"Your trained model is saved in Google Drive\")\n",
        "print(\"You can load it in the main application to test generation\")"
      ],
      "metadata": {
        "id": "generate_sample"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Summary & Next Steps"
      ],
      "metadata": {
        "id": "summary_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"TRAINING SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nðŸ“Š Dataset Statistics:\")\n",
        "if Path('../datasets/amapiano_proxy/training_metadata.csv').exists():\n",
        "    df = pd.read_csv('../datasets/amapiano_proxy/training_metadata.csv')\n",
        "    print(f\"   Total clips: {len(df)}\")\n",
        "    print(f\"   Avg score: {df['score'].mean():.2f}\")\n",
        "    print(f\"   Duration: ~{len(df) * 29 / 3600:.1f} hours\")\n",
        "\n",
        "print(\"\\nðŸ’¾ Model Location:\")\n",
        "print(\"   /content/drive/MyDrive/amapiano-training/\")\n",
        "\n",
        "print(\"\\nðŸ“ Next Steps:\")\n",
        "print(\"   1. Review training logs above for loss trends\")\n",
        "print(\"   2. Load the checkpoint in your Amapiano AI app\")\n",
        "print(\"   3. Generate test samples and evaluate quality\")\n",
        "print(\"   4. Compare to baseline MusicGen (expect 15-25% authenticity)\")\n",
        "\n",
        "print(\"\\nðŸŽ¯ Expected Results:\")\n",
        "print(\"   - Better rhythm/beat patterns (from electronic/techno)\")\n",
        "print(\"   - Some piano elements (11.7% coverage)\")\n",
        "print(\"   - Improved from baseline but not authentic Amapiano yet\")\n",
        "print(\"   - Good foundation for further fine-tuning with real samples\")\n",
        "\n",
        "print(\"\\nðŸ’° Cost:\")\n",
        "print(\"   Colab Pro: ~$10/month (if used)\")\n",
        "print(\"   This training: 1-20 hours of GPU time\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ],
      "metadata": {
        "id": "summary"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Troubleshooting\n",
        "\n",
        "**GPU not available**: Runtime > Change runtime type > GPU  \n",
        "**Out of memory**: Reduce `--batch_size` to 1  \n",
        "**Session disconnected**: Checkpoints are saved in Google Drive, just rerun from Step 5  \n",
        "**Loss is NaN**: Normal in first few steps, training will auto-recover  \n",
        "**Download fails**: Check internet, retry dataset_setup.py\n",
        "\n",
        "---\n",
        "\n",
        "## Dataset Quality Notes\n",
        "\n",
        "**Strengths:**\n",
        "- 70.5% electronic/techno (good rhythmic foundation)\n",
        "- 47.4% drums/beats (essential for Amapiano)\n",
        "- 11.7% piano (some coverage)\n",
        "- 10.4% jazzy (Private School style proxy)\n",
        "\n",
        "**Limitations:**\n",
        "- No authentic log drums (using bass as proxy)\n",
        "- Low piano coverage for piano-heavy genre\n",
        "- Genre mismatch (techno vs. house/deep house)\n",
        "- Expected authenticity: 15-25% (vs 85-95% target)\n",
        "\n",
        "**Recommendation:**\n",
        "If results are promising (>20% authenticity, good rhythm), collect 500-1,000 real Amapiano tracks and retrain for 40-50% authenticity.\n",
        "\n",
        "---\n",
        "\n",
        "## References\n",
        "\n",
        "- [MagnaTagATune Dataset](https://mirg.city.ac.uk/codeapps/the-magnatagatune-dataset)\n",
        "- [MusicGen Paper](https://arxiv.org/abs/2306.05284)\n",
        "- Project Docs: `/docs/INTERIM_DATASET_STRATEGY.md`"
      ],
      "metadata": {
        "id": "footer"
      }
    }
  ]
}

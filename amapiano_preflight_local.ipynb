{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amapiano AI - Preflight Training Pipeline (Local JupyterLab)\n",
    "\n",
    "**Purpose**: Validate the complete training pipeline locally before AWS deployment\n",
    "\n",
    "**Prerequisites**:\n",
    "- Python 3.9+\n",
    "- CUDA-compatible GPU (recommended)\n",
    "- ~10GB disk space for model + dataset\n",
    "- Jupyter Lab installed\n",
    "\n",
    "**Tests**:\n",
    "1. Environment setup\n",
    "2. Dataset preparation\n",
    "3. Model initialization\n",
    "4. Training execution\n",
    "5. Checkpoint validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Navigate to ai-service directory and install requirements\n",
    "cd ai-service\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 1: Environment Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import audiocraft\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"Audiocraft version: {audiocraft.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected - training will be VERY slow\")\n",
    "\n",
    "print(\"\\n‚úÖ TEST 1: ENVIRONMENT SETUP - PASS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 2: Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Run dataset setup script\n",
    "cd ai-service\n",
    "python dataset_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset was created\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "dataset_dir = Path(\"./ai-service/data/amapiano_dataset\")\n",
    "metadata_file = dataset_dir / \"metadata.jsonl\"\n",
    "\n",
    "if metadata_file.exists():\n",
    "    with open(metadata_file, 'r') as f:\n",
    "        samples = [json.loads(line) for line in f]\n",
    "    \n",
    "    print(f\"Dataset samples: {len(samples)}\")\n",
    "    print(f\"\\nSample entry:\")\n",
    "    print(json.dumps(samples[0], indent=2))\n",
    "    \n",
    "    # Count audio files\n",
    "    audio_files = list(dataset_dir.glob(\"*.wav\"))\n",
    "    print(f\"\\nAudio files found: {len(audio_files)}\")\n",
    "    \n",
    "    if len(audio_files) == len(samples):\n",
    "        print(\"\\n‚úÖ TEST 2: DATASET PREPARED - PASS\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå TEST 2: FAILED - Mismatch between metadata ({len(samples)}) and audio files ({len(audio_files)})\")\n",
    "else:\n",
    "    print(\"‚ùå TEST 2: FAILED - metadata.jsonl not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 3: Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiocraft.models import MusicGen\n",
    "\n",
    "print(\"Loading MusicGen model (this may take a few minutes)...\")\n",
    "model = MusicGen.get_pretrained('facebook/musicgen-small')\n",
    "\n",
    "print(f\"\\nModel loaded successfully\")\n",
    "print(f\"Model device: {next(model.lm.parameters()).device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.lm.parameters()) / 1e6:.1f}M\")\n",
    "\n",
    "# Test generation to ensure model works\n",
    "print(\"\\nTesting base model generation...\")\n",
    "model.set_generation_params(duration=5)\n",
    "wav = model.generate([\"upbeat electronic music\"])\n",
    "\n",
    "print(f\"Generated audio shape: {wav.shape}\")\n",
    "print(\"\\n‚úÖ TEST 3: MODEL INITIALIZED - PASS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local training config\n",
    "import json\n",
    "\n",
    "config = {\n",
    "    \"model_name\": \"facebook/musicgen-small\",\n",
    "    \"dataset_path\": \"./ai-service/data/amapiano_dataset\",\n",
    "    \"output_dir\": \"./training_output\",\n",
    "    \"num_epochs\": 1,\n",
    "    \"batch_size\": 2,\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"save_steps\": 50,\n",
    "    \"logging_steps\": 10,\n",
    "    \"max_duration\": 10.0,\n",
    "    \"sample_rate\": 32000,\n",
    "    \"use_fp16\": torch.cuda.is_available()\n",
    "}\n",
    "\n",
    "config_path = Path(\"./ai-service/config_local.json\")\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, indent=2, fp=f)\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "print(json.dumps(config, indent=2))\n",
    "print(f\"\\nConfig saved to: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 4 + 5: Training Execution & Checkpoint Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run training script\n",
    "!python ./ai-service/train_musicgen.py \\\n",
    "  --config ./ai-service/config_local.json \\\n",
    "  2>&1 | tee training_test.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# TEST 4: Verify training executed\n",
    "if Path('training_test.log').exists():\n",
    "    with open('training_test.log', 'r') as f:\n",
    "        log_content = f.read()\n",
    "        if 'Epoch 1/' in log_content and 'avg_loss' in log_content:\n",
    "            print(\"‚úÖ TEST 4: TRAINING EXECUTED - PASS\")\n",
    "        else:\n",
    "            print(\"‚ùå TEST 4: TRAINING FAILED - Check logs above\")\n",
    "else:\n",
    "    print(\"‚ùå TEST 4: No training log found\")\n",
    "\n",
    "# TEST 5: Verify checkpoint saved\n",
    "checkpoint_dir = Path(\"./training_output/checkpoints\")\n",
    "\n",
    "if checkpoint_dir.exists():\n",
    "    checkpoints = list(checkpoint_dir.glob(\"*.pt\")) + list(checkpoint_dir.glob(\"*.ckpt\"))\n",
    "    if checkpoints:\n",
    "        print(\"\\n‚úÖ TEST 5: CHECKPOINT SAVED - PASS\")\n",
    "        print(f\"Found {len(checkpoints)} checkpoint(s):\")\n",
    "        for ckpt in checkpoints[:5]:\n",
    "            size_mb = ckpt.stat().st_size / 1e6\n",
    "            print(f\"  - {ckpt.name} ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå TEST 5: No checkpoint files found\")\n",
    "else:\n",
    "    print(\"\\n‚ùå TEST 5: Checkpoint directory not found\")\n",
    "    print(f\"Expected: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 6 (Optional): Checkpoint Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned checkpoint and generate a sample\n",
    "import torch\n",
    "from audiocraft.models import MusicGen\n",
    "from pathlib import Path\n",
    "import IPython.display as ipd\n",
    "\n",
    "checkpoint_dir = Path(\"./training_output/checkpoints\")\n",
    "checkpoints = sorted(checkpoint_dir.glob(\"*.pt\"))\n",
    "\n",
    "if checkpoints:\n",
    "    latest_checkpoint = checkpoints[-1]\n",
    "    print(f\"Loading checkpoint: {latest_checkpoint.name}\")\n",
    "    \n",
    "    # Load base model\n",
    "    model = MusicGen.get_pretrained('facebook/musicgen-small')\n",
    "    \n",
    "    # Load fine-tuned weights\n",
    "    checkpoint = torch.load(latest_checkpoint, map_location='cpu')\n",
    "    model.lm.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(\"\\nGenerating 5-second amapiano sample...\")\n",
    "    model.set_generation_params(duration=5)\n",
    "    wav = model.generate([\"upbeat amapiano with log drums and piano\"])\n",
    "    \n",
    "    # Save and play\n",
    "    output_path = Path(\"./test_generation.wav\")\n",
    "    import torchaudio\n",
    "    torchaudio.save(str(output_path), wav[0].cpu(), sample_rate=32000)\n",
    "    \n",
    "    print(f\"\\n‚úÖ TEST 6: INFERENCE SUCCESSFUL\")\n",
    "    print(f\"Audio saved to: {output_path}\")\n",
    "    \n",
    "    # Play in notebook\n",
    "    display(ipd.Audio(str(output_path)))\n",
    "else:\n",
    "    print(\"‚ùå TEST 6: No checkpoint found to test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "If all tests pass:\n",
    "- ‚úÖ Environment is configured correctly\n",
    "- ‚úÖ Dataset generation works\n",
    "- ‚úÖ Model initialization works\n",
    "- ‚úÖ Training executes successfully\n",
    "- ‚úÖ Checkpoints are saved\n",
    "- ‚úÖ Fine-tuned model can generate audio\n",
    "\n",
    "**Next Steps**: Deploy to AWS with confidence! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Amapiano AI - Simplified Training (Dataset Already Downloaded)\n",
        "\n",
        "**Status**: ‚úÖ Dataset ready (1,582 clips in `/content/datasets/amapiano_proxy/`)\n",
        "\n",
        "**Next Step**: Train MusicGen model\n",
        "\n",
        "**Training Options**:\n",
        "- Quick Test: 1 epoch, 100 samples (~15-30 min)\n",
        "- Short: 5 epochs, full dataset (~4-6 hours)\n",
        "- Full: 20 epochs, full dataset (~16-20 hours)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Verify GPU & Dataset"
      ],
      "metadata": {
        "id": "step1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# Check GPU\n",
        "print(\"=\"*60)\n",
        "print(\"GPU CHECK\")\n",
        "print(\"=\"*60)\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"   CUDA: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"‚ùå NO GPU FOUND\")\n",
        "    print(\"‚ö†Ô∏è  Go to Runtime > Change runtime type > GPU\")\n",
        "    raise RuntimeError(\"GPU required\")\n",
        "\n",
        "# Check dataset\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATASET CHECK\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "dataset_path = Path('/content/datasets/amapiano_proxy')\n",
        "metadata_path = dataset_path / 'training_metadata.csv'\n",
        "audio_path = dataset_path / 'audio'\n",
        "\n",
        "if metadata_path.exists():\n",
        "    df = pd.read_csv(metadata_path)\n",
        "    audio_files = list(audio_path.glob('*.mp3'))\n",
        "    \n",
        "    print(f\"‚úÖ Dataset found\")\n",
        "    print(f\"   Location: {dataset_path}\")\n",
        "    print(f\"   Metadata entries: {len(df)}\")\n",
        "    print(f\"   Audio files: {len(audio_files)}\")\n",
        "    print(f\"   Total size: {sum(f.stat().st_size for f in audio_files) / 1e9:.2f} GB\")\n",
        "    print(f\"   Avg score: {df['score'].mean():.2f}\")\n",
        "    \n",
        "    print(f\"\\n   Top characteristics:\")\n",
        "    for char, count in df['characteristics'].value_counts().head(5).items():\n",
        "        pct = count / len(df) * 100\n",
        "        print(f\"   - {char}: {count} clips ({pct:.1f}%)\")\n",
        "else:\n",
        "    print(f\"‚ùå Dataset not found at {dataset_path}\")\n",
        "    print(\"   Please run the dataset setup notebook first\")\n",
        "    raise RuntimeError(\"Dataset missing\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ ALL CHECKS PASSED - Ready to train!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "verify"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Install Training Dependencies"
      ],
      "metadata": {
        "id": "step2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!pip install -q torch torchaudio transformers audiocraft accelerate\n",
        "!pip install -q datasets librosa soundfile\n",
        "\n",
        "print(\"‚úÖ Training dependencies installed\")"
      ],
      "metadata": {
        "id": "install"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Upload Training Script\n",
        "\n",
        "**Action Required**: Upload `train_musicgen.py` using the file browser on the left:\n",
        "1. Click the folder icon üìÅ on the left sidebar\n",
        "2. Click the upload button ‚¨ÜÔ∏è\n",
        "3. Select `/ai-service/train_musicgen.py` from your local files\n",
        "4. Wait for upload to complete\n",
        "5. Then run the verification cell below"
      ],
      "metadata": {
        "id": "step3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify training script is uploaded\n",
        "training_script = Path('/content/train_musicgen.py')\n",
        "\n",
        "if training_script.exists():\n",
        "    print(f\"‚úÖ Training script found ({training_script.stat().st_size / 1024:.1f} KB)\")\n",
        "else:\n",
        "    print(\"‚ùå Training script not found\")\n",
        "    print(\"   Please upload train_musicgen.py to /content/\")\n",
        "    print(\"   Use the file browser (üìÅ) on the left sidebar\")"
      ],
      "metadata": {
        "id": "verify_script"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Mount Google Drive (for saving checkpoints)"
      ],
      "metadata": {
        "id": "step4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs('/content/drive/MyDrive/amapiano-models', exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/amapiano-models/quick-test', exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/amapiano-models/5-epoch', exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/amapiano-models/20-epoch', exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Google Drive mounted\")\n",
        "print(\"   Models will be saved to: /content/drive/MyDrive/amapiano-models/\")"
      ],
      "metadata": {
        "id": "mount"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Choose Your Training Mode\n",
        "\n",
        "**Run ONLY ONE of the following cells:**"
      ],
      "metadata": {
        "id": "step5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option A: Quick Pipeline Test ‚ö°\n",
        "\n",
        "**Duration**: 15-30 minutes  \n",
        "**Purpose**: Verify everything works  \n",
        "**Config**: 1 epoch, 100 samples, batch size 1"
      ],
      "metadata": {
        "id": "option_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!python /content/train_musicgen.py \\\n",
        "  --data_dir /content/datasets/amapiano_proxy/audio \\\n",
        "  --metadata /content/datasets/amapiano_proxy/training_metadata.csv \\\n",
        "  --output_dir /content/drive/MyDrive/amapiano-models/quick-test \\\n",
        "  --epochs 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --max_samples 100 \\\n",
        "  --learning_rate 1e-5\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ QUICK TEST COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(\"Check the output above for:\")\n",
        "print(\"  - Loss values (should decrease)\")\n",
        "print(\"  - Any error messages\")\n",
        "print(\"  - Checkpoint saved to Google Drive\")\n",
        "print(\"\\nIf successful, you can run the 5-epoch or 20-epoch training next.\")"
      ],
      "metadata": {
        "id": "quick_test"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option B: Short Training (5 epochs) üöÄ\n",
        "\n",
        "**Duration**: 4-6 hours  \n",
        "**Purpose**: Get initial trained model  \n",
        "**Config**: 5 epochs, full dataset, batch size 2"
      ],
      "metadata": {
        "id": "option_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!python /content/train_musicgen.py \\\n",
        "  --data_dir /content/datasets/amapiano_proxy/audio \\\n",
        "  --metadata /content/datasets/amapiano_proxy/training_metadata.csv \\\n",
        "  --output_dir /content/drive/MyDrive/amapiano-models/5-epoch \\\n",
        "  --epochs 5 \\\n",
        "  --batch_size 2 \\\n",
        "  --learning_rate 1e-5 \\\n",
        "  --save_every 500\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ 5-EPOCH TRAINING COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(\"Model saved to: /content/drive/MyDrive/amapiano-models/5-epoch/\")\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"  1. Download the model from Google Drive\")\n",
        "print(\"  2. Test generation in your app\")\n",
        "print(\"  3. Evaluate authenticity (target: 15-25%)\")"
      ],
      "metadata": {
        "id": "short_train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option C: Full Training (20 epochs) üéØ\n",
        "\n",
        "**Duration**: 16-20 hours  \n",
        "**Purpose**: Best results with current dataset  \n",
        "**Config**: 20 epochs, full dataset, batch size 2  \n",
        "**Note**: Requires Colab Pro or run overnight"
      ],
      "metadata": {
        "id": "option_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!python /content/train_musicgen.py \\\n",
        "  --data_dir /content/datasets/amapiano_proxy/audio \\\n",
        "  --metadata /content/datasets/amapiano_proxy/training_metadata.csv \\\n",
        "  --output_dir /content/drive/MyDrive/amapiano-models/20-epoch \\\n",
        "  --epochs 20 \\\n",
        "  --batch_size 2 \\\n",
        "  --learning_rate 1e-5 \\\n",
        "  --save_every 500\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ FULL 20-EPOCH TRAINING COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(\"Model saved to: /content/drive/MyDrive/amapiano-models/20-epoch/\")\n",
        "print(\"\\nThis is your best model with the MagnaTagATune dataset.\")\n",
        "print(\"\\nExpected performance:\")\n",
        "print(\"  - Authenticity: 15-25% (vs 10-20% baseline)\")\n",
        "print(\"  - Better rhythms and beats\")\n",
        "print(\"  - Some piano elements\")\n",
        "print(\"  - Foundation for further training with real Amapiano samples\")"
      ],
      "metadata": {
        "id": "full_train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Monitor Training Progress"
      ],
      "metadata": {
        "id": "step6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell helps you monitor training while it's running\n",
        "# Run this in a separate cell while training is ongoing\n",
        "\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "# Check which training is running\n",
        "output_dirs = {\n",
        "    'Quick Test': '/content/drive/MyDrive/amapiano-models/quick-test',\n",
        "    '5 Epoch': '/content/drive/MyDrive/amapiano-models/5-epoch',\n",
        "    '20 Epoch': '/content/drive/MyDrive/amapiano-models/20-epoch'\n",
        "}\n",
        "\n",
        "print(\"Checking for training progress...\\n\")\n",
        "\n",
        "for name, path in output_dirs.items():\n",
        "    checkpoint_dir = Path(path)\n",
        "    if checkpoint_dir.exists():\n",
        "        checkpoints = list(checkpoint_dir.glob('*.pt')) + list(checkpoint_dir.glob('*.pth'))\n",
        "        if checkpoints:\n",
        "            latest = max(checkpoints, key=lambda p: p.stat().st_mtime)\n",
        "            age_seconds = time.time() - latest.stat().st_mtime\n",
        "            age_minutes = age_seconds / 60\n",
        "            \n",
        "            print(f\"üìä {name}:\")\n",
        "            print(f\"   Latest checkpoint: {latest.name}\")\n",
        "            print(f\"   Size: {latest.stat().st_size / 1e6:.1f} MB\")\n",
        "            print(f\"   Last updated: {age_minutes:.1f} minutes ago\")\n",
        "            print(f\"   Total checkpoints: {len(checkpoints)}\")\n",
        "            print()\n",
        "\n",
        "print(\"üí° Tip: Rerun this cell every few minutes to track progress\")"
      ],
      "metadata": {
        "id": "monitor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Verify Training Completed Successfully"
      ],
      "metadata": {
        "id": "step7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"TRAINING VERIFICATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "output_dirs = {\n",
        "    'Quick Test': '/content/drive/MyDrive/amapiano-models/quick-test',\n",
        "    '5 Epoch': '/content/drive/MyDrive/amapiano-models/5-epoch',\n",
        "    '20 Epoch': '/content/drive/MyDrive/amapiano-models/20-epoch'\n",
        "}\n",
        "\n",
        "for name, path in output_dirs.items():\n",
        "    checkpoint_dir = Path(path)\n",
        "    if checkpoint_dir.exists():\n",
        "        checkpoints = list(checkpoint_dir.glob('*.pt')) + list(checkpoint_dir.glob('*.pth'))\n",
        "        \n",
        "        if checkpoints:\n",
        "            print(f\"\\nüì¶ {name}:\")\n",
        "            print(f\"   Location: {path}\")\n",
        "            print(f\"   Checkpoints found: {len(checkpoints)}\")\n",
        "            \n",
        "            # Try to load the latest checkpoint\n",
        "            latest = max(checkpoints, key=lambda p: p.stat().st_mtime)\n",
        "            print(f\"   Latest: {latest.name} ({latest.stat().st_size / 1e6:.1f} MB)\")\n",
        "            \n",
        "            try:\n",
        "                ckpt = torch.load(latest, map_location='cpu')\n",
        "                print(f\"   ‚úÖ Checkpoint is loadable\")\n",
        "                \n",
        "                if 'epoch' in ckpt:\n",
        "                    print(f\"   Epoch: {ckpt['epoch']}\")\n",
        "                if 'loss' in ckpt:\n",
        "                    print(f\"   Loss: {ckpt['loss']:.4f}\")\n",
        "                if 'model_state_dict' in ckpt:\n",
        "                    print(f\"   ‚úÖ Model weights present\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ö†Ô∏è  Warning: {str(e)[:100]}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\\n‚úÖ Verification complete!\")\n",
        "print(\"\\nYour trained models are saved in Google Drive and will persist\")\n",
        "print(\"even after this Colab session ends.\")"
      ],
      "metadata": {
        "id": "verify_complete"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary & Next Steps"
      ],
      "metadata": {
        "id": "summary"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"TRAINING COMPLETE - SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nüìä Dataset Used:\")\n",
        "print(\"   - Source: MagnaTagATune (filtered)\")\n",
        "print(\"   - Clips: 1,582\")\n",
        "print(\"   - Duration: ~12.7 hours\")\n",
        "print(\"   - Characteristics: Electronic/techno with drums, piano, bass\")\n",
        "\n",
        "print(\"\\nüíæ Model Location:\")\n",
        "print(\"   - Google Drive: /MyDrive/amapiano-models/\")\n",
        "print(\"   - Download to use in your app\")\n",
        "\n",
        "print(\"\\nüéØ Expected Results:\")\n",
        "print(\"   - Baseline MusicGen: 10-20% Amapiano authenticity\")\n",
        "print(\"   - Your trained model: 15-25% authenticity (estimated)\")\n",
        "print(\"   - Improvement: Better rhythm/beat patterns\")\n",
        "print(\"   - Limitation: Not authentic Amapiano yet (dataset constraint)\")\n",
        "\n",
        "print(\"\\nüìù Next Steps:\")\n",
        "print(\"   1. Download your trained model from Google Drive\")\n",
        "print(\"   2. Load it in your Amapiano AI application\")\n",
        "print(\"   3. Generate test samples with different prompts\")\n",
        "print(\"   4. Evaluate authenticity compared to baseline\")\n",
        "print(\"   5. If promising (>20%), collect real Amapiano samples\")\n",
        "print(\"   6. Fine-tune on 500-1000 real tracks for 40-50% authenticity\")\n",
        "\n",
        "print(\"\\nüí° Recommendations:\")\n",
        "print(\"   - If results show improvement, proceed to Phase 3\")\n",
        "print(\"   - Collect authentic Amapiano tracks from:\")\n",
        "print(\"     ‚Ä¢ Kabza De Small\")\n",
        "print(\"     ‚Ä¢ DJ Maphorisa\")\n",
        "print(\"     ‚Ä¢ Kelvin Momo\")\n",
        "print(\"     ‚Ä¢ Focalistic\")\n",
        "print(\"   - Target: 500-1000 tracks for next training phase\")\n",
        "print(\"   - Expected authenticity with real data: 40-50%\")\n",
        "\n",
        "print(\"\\nüí∞ Cost Breakdown:\")\n",
        "print(\"   - Colab (free tier): $0\")\n",
        "print(\"   - Colab Pro (if used): $10/month\")\n",
        "print(\"   - GPU time: Already included\")\n",
        "print(\"   - Total for this phase: $0-10\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ Congratulations on completing the training!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "final_summary"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Troubleshooting Guide\n",
        "\n",
        "### GPU Issues\n",
        "**Problem**: No GPU available  \n",
        "**Solution**: Runtime > Change runtime type > Hardware accelerator: GPU > Save\n",
        "\n",
        "### Memory Issues\n",
        "**Problem**: CUDA out of memory  \n",
        "**Solution**: Reduce `--batch_size` to 1 in training command\n",
        "\n",
        "### Session Disconnected\n",
        "**Problem**: Colab session timed out during training  \n",
        "**Solution**: Checkpoints are saved in Google Drive. Training will resume from last checkpoint if you rerun the same command\n",
        "\n",
        "### Training Script Not Found\n",
        "**Problem**: `train_musicgen.py` not found  \n",
        "**Solution**: \n",
        "1. Use file browser (üìÅ) on left\n",
        "2. Click upload button (‚¨ÜÔ∏è)\n",
        "3. Select `train_musicgen.py` from `/ai-service/` folder\n",
        "4. Verify it appears in `/content/`\n",
        "\n",
        "### Loss is NaN\n",
        "**Problem**: Training shows NaN loss  \n",
        "**Solution**: This can happen in early steps. If it persists after 100 steps, reduce learning rate to 5e-6\n",
        "\n",
        "### Slow Training\n",
        "**Problem**: Training is very slow  \n",
        "**Expected**: \n",
        "- Quick test: 15-30 min\n",
        "- 5 epochs: 4-6 hours\n",
        "- 20 epochs: 16-20 hours\n",
        "\n",
        "If significantly slower, check GPU is being used (Step 1)\n",
        "\n",
        "---\n",
        "\n",
        "## Files You Need to Upload\n",
        "\n",
        "From your local `/ai-service/` folder:\n",
        "1. ‚úÖ `train_musicgen.py` - Main training script (REQUIRED)\n",
        "\n",
        "Everything else is handled by pip install.\n",
        "\n",
        "---\n",
        "\n",
        "## References\n",
        "\n",
        "- **MagnaTagATune Dataset**: https://mirg.city.ac.uk/codeapps/the-magnatagatune-dataset\n",
        "- **MusicGen Paper**: https://arxiv.org/abs/2306.05284\n",
        "- **AudioCraft GitHub**: https://github.com/facebookresearch/audiocraft\n",
        "- **Project Docs**: See `/docs/` folder in repository\n",
        "\n",
        "---\n",
        "\n",
        "## Contact & Support\n",
        "\n",
        "If you encounter issues:\n",
        "1. Check the troubleshooting section above\n",
        "2. Review training logs for error messages\n",
        "3. Verify all prerequisites (GPU, dataset, script uploaded)\n",
        "4. Check Google Drive has sufficient space (~5-10 GB)\n",
        "\n",
        "---\n",
        "\n",
        "**Version**: 1.0  \n",
        "**Last Updated**: 2025-11-29  \n",
        "**Status**: Ready for production use ‚úÖ"
      ],
      "metadata": {
        "id": "footer"
      }
    }
  ]
}
